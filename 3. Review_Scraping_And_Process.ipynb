{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Restaurant Reviews from Yelp Using Business Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the comment, comment_count and date by descending order\n",
    "#if the comment_count is greater than 100, we take the first 100 comment\n",
    "#if the comment_count is less than 100, we take as many comment as we can \n",
    "#if the number of reviews written by one reviewer is less than 10, we consider the review as unvalued\n",
    "def get_new_date(alias,N=100):\n",
    "    url = 'https://www.yelp.com/biz/'+alias+'?sort_by=date_desc'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"==200\")\n",
    "        return None,None,None\n",
    "    response_page = BeautifulSoup(response.content,'lxml')\n",
    "    review_abbre = response_page.find_all('script',type='application/ld+json')\n",
    "    try:\n",
    "        review_text= json.loads(review_abbre[-1].get_text())\n",
    "        date = review_text.get('review')[0].get('datePublished')\n",
    "    except:\n",
    "        print(\"1st try goes wrong\")\n",
    "        return None,None,None\n",
    "    #date = review_text.get('review')[0].get('datePublished')\n",
    "    count_list,author_list,review_list,rate_list = [],[],[],[]\n",
    "    \n",
    "    while len(count_list)< N and response.status_code == 200:\n",
    "\n",
    "        total_author = response_page.find_all('div',{'class',\"review review--with-sidebar\"})\n",
    "        for all_review in total_author:\n",
    "            count = all_review.find('li',{'class':'review-count'}).find('b').get_text()\n",
    "            if int(count)>=10:\n",
    "                try:\n",
    "                    count_list.append(count)\n",
    "                    author_list.append(all_review.find('a',{'class','user-display-name'}).get_text())\n",
    "                    review_list.append(all_review.find('p',{'lang':'en'}).get_text())\n",
    "                    rate_list.append(float(all_review.find('img',class_='offscreen').get('alt')[:3]))\n",
    "                except:\n",
    "                    print(\"2nd try goes wrong\")\n",
    "                    return None, None, None\n",
    "        try:\n",
    "            url = response_page.find_all('a',{'class':'u-decoration-none next pagination-links_anchor'})[0].get('href')\n",
    "        except:\n",
    "            print(\"3rd try goes wrong\")\n",
    "            break\n",
    "        response = requests.get(url)\n",
    "        response_page = BeautifulSoup(response.content,'lxml')\n",
    "    \n",
    "    reviews=' '.join(review_list)\n",
    "    avg_rate = sum(rate_list)/len(rate_list)\n",
    "    \n",
    "    return date,reviews,avg_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the oldest comment by ascending order\n",
    "def get_old_date(alias):\n",
    "    url = 'https://www.yelp.com/biz/'+alias+'?sort_by=date_asc'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    contents = BeautifulSoup(response.content,'lxml')\n",
    "    review_abbre = contents.find_all('script',type='application/ld+json')\n",
    "    try:\n",
    "        review_text= json.loads(review_abbre[-1].get_text())\n",
    "        date = review_text.get('review')[0].get('datePublished')\n",
    "    except:\n",
    "        return None\n",
    "    #date = review_text.get('review')[0].get('datePublished')\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the original data and add new columns\n",
    "df=pd.read_pickle('italian_551.pkl')\n",
    "N=0\n",
    "while N<=551: \n",
    "    business_new = df.iloc[N:N+20]\n",
    "    business_new['old_date'] = business_new['alias'].apply(get_old_date)\n",
    "    #try to not active the reCaptcha\n",
    "    time.sleep(10)\n",
    "    business_new['new_date_review_rate'] = business_new['alias'].apply(get_new_date)\n",
    "    business_new['new_date']=business_new['new_date_review_rate'].apply(lambda x:x[0])\n",
    "    business_new['review']=business_new['new_date_review_rate'].apply(lambda x:x[1])\n",
    "    business_new['avg_rate']=business_new['new_date_review_rate'].apply(lambda x:x[2])\n",
    "    business_new.to_pickle(\"./review/italian_{}.pkl\".format(N))\n",
    "    time.sleep(10)\n",
    "    print(N)\n",
    "    N+=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the segmental dataframe to one\n",
    "df=pd.read_pickle('./review/italian_0.pkl')\n",
    "for x in range(20,560,20):\n",
    "    new=pd.read_pickle('./review/italian_{}.pkl'.format(x))\n",
    "    df=pd.concat([df,new])\n",
    "df.to_pickle('italian_review_551.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9       (2019-04-06, I met a friend at this restaurant...\n",
       "10      (2019-04-09, Awesome food, delicious wines, ex...\n",
       "15      (2019-04-15, Let me start off by saying that t...\n",
       "24      (2019-04-13, This place was amazing!! Neapolit...\n",
       "27      (2019-04-15, I was under the impressions based...\n",
       "35      (2019-04-14, I visited this location yesterday...\n",
       "42      (2019-04-16, Fumo is one of those classic lunc...\n",
       "51      (2019-04-06, My wife and I had a wonderful mea...\n",
       "61      (2019-02-22, In years of yore, Italians had th...\n",
       "65      (2019-04-12, Walked in here for two slices and...\n",
       "71      (2019-04-11, Small local restaurant.   For som...\n",
       "73      (2019-04-14, I've eaten here twice and am very...\n",
       "74      (2019-04-01, Always a great experience here. T...\n",
       "83      (2019-02-19, (Based on a single Summer 2015 vi...\n",
       "95      (2019-04-09, This fish ....caught me.  I highl...\n",
       "96      (2019-04-16, Went with my friend and it was de...\n",
       "120     (2019-04-10, The first time I was there, I had...\n",
       "125     (2019-04-12, Doesnt get better and totally liv...\n",
       "147     (2019-03-31, Cute Italian spot in Morningside ...\n",
       "151     (2019-04-15, This is the best kept secret in t...\n",
       "175     (2019-03-24, Well, I wanted to give this place...\n",
       "181     (2019-04-16, Really great little hidden gem on...\n",
       "186     (2019-04-03, This small, cozy restaurant has s...\n",
       "244     (2019-03-31, Finally a good Italian Restaurant...\n",
       "245     (2019-03-30, This place is tiny but the food i...\n",
       "272     (2019-04-14, Today (March, 31, 2019 between 8p...\n",
       "277     (2019-04-16, Had an early dinner with two frie...\n",
       "287     (2019-03-29, Love this place, but why not have...\n",
       "295     (2019-04-06, a great mom & pop neighborhood sp...\n",
       "301     (2019-04-11, Tasty old school pizza slices and...\n",
       "                              ...                        \n",
       "4159    (2019-04-04, I ordered delivery from here. It ...\n",
       "4176    (2019-04-14, This has always been a common pla...\n",
       "4186    (2019-03-07, This upper east side place is del...\n",
       "4197    (2019-04-06, A great measure of just how good ...\n",
       "4199    (2019-04-18, Nothing fancy.  Not enough sauce ...\n",
       "4201                                   (None, None, None)\n",
       "4204    (2019-04-01, If you're looking for an intimate...\n",
       "4207    (2019-04-05, Enjoyed the grandma pie, but not ...\n",
       "4218    (2019-04-12, Had pepperoni & chicken parmigian...\n",
       "4221    (2019-04-16, Honestly, i have always been skep...\n",
       "4225    (2019-04-14, 5 open tables for 2 at 6:30 and w...\n",
       "4236    (2019-04-18, my favorite west side go to excel...\n",
       "4237    (2019-03-28, Made a reservation for 830 and wa...\n",
       "4242    (2019-04-06, Went at 9 pm and the service was ...\n",
       "4253    (2019-04-03, Meh. Nothing noteworthy. The serv...\n",
       "4256    (2019-04-04, Incredible service, ambiance and ...\n",
       "4266    (2019-04-14, The service SUCKS ASS.  Food is n...\n",
       "4271    (2019-03-15, Decided to try this place on a wh...\n",
       "4290    (2019-04-02, This is a really good lunch place...\n",
       "4315    (2019-04-07, I'm glad marinara opened on the U...\n",
       "4364    (2019-04-16, Ordered fried mixed seafood and o...\n",
       "4374    (2019-03-31, The food was really really good, ...\n",
       "4433    (2019-04-13, I see this is a new expansion of ...\n",
       "4434    (2019-03-17, I really like the ambiance of Il ...\n",
       "4442    (2019-03-27, I've lived and driven by this pla...\n",
       "4521    (2019-01-27, I prefer smaller thin crust pizza...\n",
       "4545    (2018-04-30, I'm a big fan of Sbarro. I think ...\n",
       "4563    (2019-03-24, This place used to be amazing! Th...\n",
       "4617    (2018-12-23, Plain slice was deeply underwhelm...\n",
       "4630    (2019-02-28, Can't beat their dollar slices. A...\n",
       "Name: new_date_review_rate, Length: 551, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_date_review_rate']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
